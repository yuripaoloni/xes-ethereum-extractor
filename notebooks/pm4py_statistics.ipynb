{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "\n",
    "from pathlib import Path\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.filtering.log.timestamp import timestamp_filter\n",
    "from pm4py.algo.filtering.log.start_activities import start_activities_filter\n",
    "from pm4py.statistics.traces.generic.log import case_statistics\n",
    "from pm4py.visualization.graphs import visualizer as graphs_visualizer\n",
    "from pm4py import view_dotted_chart, view_events_distribution_graph\n",
    "\n",
    "from utils import export_dictionary\n",
    "\n",
    "file_name = \"../data/logs\"\n",
    "\n",
    "log = xes_importer.apply(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variants list and their respective count    \n",
    "variants_count = case_statistics.get_variant_statistics(log)\n",
    "variants_count = sorted(\n",
    "    variants_count, key=lambda x: x['count'], reverse=True)\n",
    "export_dictionary(\n",
    "    variants_count, \"data/statistics/variants\",  f\"{Path(file_name).name}_variants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start activities list and their respective count\n",
    "start_activities_count = start_activities_filter.get_start_activities(log)\n",
    "start_activities_count = sorted(\n",
    "    start_activities_count.items(), key=lambda x: x[1],  reverse=True)\n",
    "sorted_start_activities_count = {k: v for k, v in start_activities_count}\n",
    "export_dictionary(sorted_start_activities_count,\n",
    "                    \"data/statistics/start_activities\", f\"{Path(file_name).name}_start_activities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distribution of events over time. it helps to understand in which time intervals the greatest number of events is recorded\n",
    "x, y = attributes_filter.get_kde_date_attribute(\n",
    "    log, attribute=\"time:timestamp\")\n",
    "\n",
    "gviz = graphs_visualizer.apply_plot(\n",
    "    x, y, variant=graphs_visualizer.Variants.DATES)\n",
    "graphs_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charts for distribution of events over time. distr_type can be: hours, days_week, days_month, months, years.\n",
    "distr_type = \"years\"\n",
    "\n",
    "view_events_distribution_graph(log, distr_type, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dotted chart is a classic visualization of the events inside an event log across different dimensions (X, Y, colors).\n",
    "# Each event of the event log is corresponding to a point. X = timestamp, Y = case index, colors = concept:name (tx function name)\n",
    "\n",
    "# for the full log filtering is needed (only April 2022 is removed). an out of memory expection is returned\n",
    "log = timestamp_filter.filter_traces_contained(\n",
    "    log, \"2018-01-01 00:00:00\", \"2022-03-15 13:15:47\")\n",
    "view_dotted_chart(log, format=\"svg\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
