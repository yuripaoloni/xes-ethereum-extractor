{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the data generated with [Ethtx](https://github.com/EthTx) using their [beta data warehouses](https://tokenflow.live/blog/edw-open). The data refers to the transactions of the [LANDProxy](https://etherscan.io/address/0xf87e31492faf9a91b02ee0deaad50d51d56d5d4d) contract and the subcalls of each transaction.\n",
    "\n",
    "The goal is to produce a dataframe for each unique `FUNCTION_NAME` contained in the data. On such dataframes, all the transactions and subcalls for the `FUNCTION_NAME` are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9724\n",
      "Index(['LOAD_ID', 'CHAIN_ID', 'BLOCK', 'TIMESTAMP', 'TX_HASH', 'CALL_ID',\n",
      "       'CALL_TYPE', 'FROM_ADDRESS', 'FROM_NAME', 'TO_ADDRESS', 'TO_NAME',\n",
      "       'FUNCTION_SIGNATURE', 'FUNCTION_NAME', 'VALUE', 'ARGUMENTS',\n",
      "       'RAW_ARGUMENTS', 'OUTPUTS', 'RAW_OUTPUTS', 'GAS_USED', 'ERROR',\n",
      "       'STATUS', 'ORDER_INDEX', 'DECODING_STATUS', 'STORAGE_ADDRESS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# path = r'../data/LAND_decoded_calls'\n",
    "# all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "# df = pd.concat((pd.read_csv(f,  sep=\",\", engine=\"python\", escapechar='\\\\')\n",
    "#                for f in all_files))\n",
    "\n",
    "df = pd.read_csv(r'../data/LAND_decoded_calls\\LAND_decoded_calls_0_0_0.csv', sep=\",\", engine=\"python\", escapechar='\\\\')\n",
    "\n",
    "print(df.shape[0])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since transactions can happen inside the same block, they will have the same timestamp. To give a time order to the records, we sort them using `TIMESTAMP` and `ORDER_INDEX` fields and add incrementally 1 second to records with same timestamp.\n",
    "\n",
    "Moreover, we add the `ORIGIN_ADDRESS` field to the transaction record and to the related subcalls, and the `FUNCTION_NAME` of the subcalls is prefixed with the `FROM_NAME` (e.g. `LAND.approve`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ERROR'] == '\\\\N'] # remove errored transactions\n",
    "\n",
    "df = df.sort_values(by=[\"TIMESTAMP\", \"ORDER_INDEX\"]) # sort by TIMESTAMP and ORDER_INDEX\n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP']) # convert TIMESTAMP from object to datetime\n",
    "\n",
    "last_timestamp = \"\"\n",
    "counter = 1\n",
    "user_address = \"\"\n",
    "function_name = \"\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if(row[\"TIMESTAMP\"] == last_timestamp):\n",
    "        counter = counter + 1\n",
    "        new_timestamp = pd.to_datetime(row[\"TIMESTAMP\"] + pd.to_timedelta(counter, unit='s'))\n",
    "    else:\n",
    "        last_timestamp = row[\"TIMESTAMP\"]\n",
    "        counter = 1\n",
    "        new_timestamp = pd.to_datetime(row[\"TIMESTAMP\"] + pd.to_timedelta(counter, unit='s')) \n",
    "\n",
    "    df.at[index,'TIMESTAMP'] = new_timestamp\n",
    "\n",
    "    if(row[\"CALL_ID\"] == \"\\\\N\"):\n",
    "        user_address = row[\"FROM_ADDRESS\"]\n",
    "        function_name = row[\"FUNCTION_NAME\"]\n",
    "    else:\n",
    "        df.at[index, 'FUNCTION_NAME'] = f\"{function_name}_{row['FUNCTION_NAME']}\"\n",
    "\n",
    "    df.at[index, 'ORIGIN_ADDRESS'] = user_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `.xes` log with the `ORIGIN_ADDRESS` as trace key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "exporting log, completed traces :: 100%|██████████| 848/848 [00:00<00:00, 1095.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "\n",
    "df = dataframe_utils.convert_timestamp_columns_in_df(\n",
    "    df)\n",
    "df = df.sort_values(\n",
    "    by=[\"TIMESTAMP\"])\n",
    "\n",
    "#! remove the records with `CALL_ID == \\\\N` since we are interested only on the internal calls\n",
    "df = df[df['CALL_ID'] != '\\\\N']\n",
    "\n",
    "# remove unnecessary fields\n",
    "df.drop([\"LOAD_ID\", \"CHAIN_ID\", \"VALUE\", \"RAW_ARGUMENTS\", \"RAW_OUTPUTS\", \"GAS_USED\", \"DECODING_STATUS\", \"STORAGE_ADDRESS\", \"ERROR\", \"STATUS\"], axis=1, inplace=True)\n",
    "\n",
    "# drop null values (in case any)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# create columns: from -> case:concept:name, inputFunctionName -> concept:name, timeStamp -> time:timestamp, from -> org:resource\n",
    "df[\"org:resource\"] = df[\"FROM_ADDRESS\"]\n",
    "df[\"case:concept:name\"] = df[\"ORIGIN_ADDRESS\"]\n",
    "df[\"time:timestamp\"] = df[\"TIMESTAMP\"]\n",
    "df[\"concept:name\"] = df[\"FUNCTION_NAME\"]\n",
    "\n",
    "# specify that the field identifying the case identifier attribute is the field with name 'case:concept:name'\n",
    "parameters = {\n",
    "    log_converter.Variants.TO_EVENT_LOG.value.Parameters.CASE_ID_KEY: 'case:concept:name'}\n",
    "log = log_converter.apply(df, parameters=parameters,\n",
    "                          variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "\n",
    "xes_exporter.apply(\n",
    "    log, \"../data/logs/land_proxy_internal.xes\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1527373efda72fa2755c1bf8e28aa37d44fcfaa765722a53896873e9ccde169f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
